{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DP_CGAN_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K1HkyrBeWiW",
        "colab_type": "text"
      },
      "source": [
        "# DP-CGAN: Differentially Private Conditional GAN - TensorFlow 2\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ricardocarvalhods/dpcgan/blob/master/DP_CGAN_MNIST.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/ricardocarvalhods/dpcgan/blob/master/DP_CGAN_MNIST.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "</table>\n",
        "<br/><br/><br/>\n",
        "\n",
        "**Author**: \n",
        "- Ricardo S. Carvalho\n",
        "    - PhD Student at Simon Fraser University\n",
        "    - Please feel free to get in touch via (rsilvaca [at] sfu [dot] ca)\n",
        "    - Personal website: [ricardocarvalho.ca](http://ricardocarvalho.ca/)\n",
        "\n",
        "**Content**:\n",
        "- This notebook contains the implementation of a Differentially Private Conditional GAN, originally described on [Torkzadehmahani et al. 2019](http://openaccess.thecvf.com/content_CVPRW_2019/papers/CV-COPS/Torkzadehmahani_DP-CGAN_Differentially_Private_Synthetic_Data_and_Label_Generation_CVPRW_2019_paper.pdf).\n",
        "- We include a TF 2 version implemented from scratch, using the Keras API and a `tf.GradientTape` training loop.\n",
        "- To successfully use DP on a Conditional GAN, we design a **custom optimizer**.\n",
        "- We include results on the MNIST dataset.\n",
        "\n",
        "**References**:\n",
        "- The GAN implementation was inspired by TensorFlow's tutorial on Convolutional GANs, which can be found [here](https://www.tensorflow.org/tutorials/generative/dcgan).\n",
        "- The DP integration was inspired by TF Privacy's tutorial on DPSGD on eager Keras, available [on this link](https://github.com/tensorflow/privacy/blob/master/tutorials/mnist_dpsgd_tutorial_eager.py).\n",
        "- The DP conditional application follows ideas from the original TF 1.15 code on [this github repository](https://github.com/reihaneh-torkzadehmahani/DP-CGAN), with some modifications to clear inconsistencies in the code. We further discussed the differences in a [report](https://github.com/ricardocarvalhods/dpcgan/blob/master/report.pdf).\n",
        "\n",
        "**Acknowledgments**:\n",
        "- We thank the **first author of the DP-CGAN**, Reihaneh Torkzadehmahani, for clarifying the settings used in their work and for fruitful discussions about the framework. \n",
        "- Additionally, we thank **Google privacy engineers** Galen Andrew, Steve Chien and Brendan McMahan for helping with important questions about TF privacy.\n",
        "\n",
        "**Pre-requisites**:\n",
        "- We consider the following are known to anyone using this notebook:\n",
        "    - Generative Adversarial Networks (GANs): Knowledge of how they work, especially loss functions.\n",
        "        - Suggestion of reference: [Udacity videos from Goodfellow on GANs](https://mc.ai/generative-adversarial-networks-gans-by-udacity-the-complete-youtube-playlist/).\n",
        "    - Differential Privacy (DP): Basic knowledge to know what the privacy parameters mean when stating a mechanism is (epsilon, delta)-differentially private.\n",
        "        - DP-SGD: Understanding main modifications needed to SGD to make it differentially private.\n",
        "        - Suggestion of reference: [blog post of DP-SGD on TF](http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html) and [tutorials on TF Privacy](https://github.com/tensorflow/privacy/tree/master/tutorials)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gISeunA2eWie",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Introduction\n",
        "\n",
        "We implement a conditional GAN ([Mirza and Osindero, 2014](https://arxiv.org/abs/1411.1784)), which is a GAN where both Discriminator and Generator are conditioned on some information, such as labels. Additionally, we want to protect the privacy of the training data, as we know ([Hayes et. al, 2017](https://arxiv.org/abs/1705.07663)) it is possible to perform membership inference on it. So to address this problem, we use differential privacy on the GAN training by applying DP-SGD from [Abadi et. al, 2016](https://arxiv.org/abs/1607.00133).\n",
        "\n",
        "Generally, DP-SGD enforces privacy by clipping gradients individually and adding Gaussian noise -- to learn more about DP-SGD and its use with TF, I recommend [this excellent post](http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html). Since only the Discriminator has access to the private data, we have to use DP-SGD only during the Discriminator training. \n",
        "\n",
        "However, Discriminator learns via both private data and the generated data (output of Generator). Since the generated data is not sensitive, as it is created from noise, we do not need to apply DP-SGD and modify the gradients for the discriminator when learning from the generated data. For this reason we modify the discriminator's optimizer to only add noise to the gradients when learning from the real data, and not add noise when learning from the generated data. Moreover, we combine gradients from both real and generated on a single update step, following the approach from [Torkzadehmahani et al. 2019](http://openaccess.thecvf.com/content_CVPRW_2019/papers/CV-COPS/Torkzadehmahani_DP-CGAN_Differentially_Private_Synthetic_Data_and_Label_Generation_CVPRW_2019_paper.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgUl3Ow_eWif",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## Imports\n",
        "\n",
        "### Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBWDYtHbeWih",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT = '/content/gdrive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRNp7wkueWio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Connect to Google Drive\n",
        "# Only run this cell if on Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount(ROOT, force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ER5Q8cbTeWit",
        "colab_type": "text"
      },
      "source": [
        "### General imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lAnvkkKKj7yU",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gg5B1yY7kA6w",
        "outputId": "2c6f80c3-a9bb-42f5-a19a-cc3b8df84803",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IOSmuaY0kBXR",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ejbzd6zdDLMy",
        "outputId": "c6d367c8-36d1-44a6-fe5b-3331d203afe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qDwo4ClNlTts",
        "outputId": "b6a1c253-8541-4f99-cf77-fe6e84877b55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# To use Differential Privacy\n",
        "!pip install tensorflow_privacy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_privacy in /usr/local/lib/python3.6/dist-packages (0.2.2)\n",
            "Requirement already satisfied: mpmath in /usr/local/lib/python3.6/dist-packages (from tensorflow_privacy) (1.1.0)\n",
            "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from tensorflow_privacy) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /tensorflow-2.1.0/python3.6 (from scipy>=0.17->tensorflow_privacy) (1.18.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUrs35HjeWjG",
        "colab_type": "code",
        "outputId": "a168447b-70f0-4fd7-d774-18722ea465cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# To create models for validation and testing\n",
        "!pip install sklearn"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /tensorflow-2.1.0/python3.6 (from scikit-learn->sklearn) (1.18.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gjGtjZWokG36",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "from tensorflow.keras import layers, models\n",
        "import tensorflow.keras.backend as K\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy\n",
        "from tensorflow_privacy.privacy.optimizers.dp_optimizer import DPGradientDescentGaussianOptimizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0L-DdHOeWjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method obtained from https://stackoverflow.com/questions/41123879/numpy-random-choice-in-tensorflow\n",
        "def _random_choice(inputs, n_samples):\n",
        "    \"\"\"\n",
        "    With replacement.\n",
        "    Params:\n",
        "      inputs (Tensor): Shape [n_states, n_features]\n",
        "      n_samples (int): The number of random samples to take.\n",
        "    Returns:\n",
        "      sampled_inputs (Tensor): Shape [n_samples, n_features]\n",
        "    \"\"\"\n",
        "    # (1, n_states) since multinomial requires 2D logits.\n",
        "    uniform_log_prob = tf.expand_dims(tf.zeros(tf.shape(inputs)[0]), 0)\n",
        "\n",
        "    ind = tf.compat.v1.multinomial(uniform_log_prob, n_samples)\n",
        "    ind = tf.squeeze(ind, 0, name=\"random_choice_ind\")  # (n_samples,)\n",
        "\n",
        "    return tf.gather(inputs, ind, name=\"random_choice\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_2WUvm2LeWjS",
        "colab_type": "code",
        "outputId": "a7314624-e3b6-4a0a-ae97-900cd543b8f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "ConvergenceWarning('ignore')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sklearn.exceptions.ConvergenceWarning('ignore')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AqszHUqweWjW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Method obtained from https://github.com/reihaneh-torkzadehmahani/DP-CGAN\n",
        "def compute_fpr_tpr_roc(Y_test, Y_score):\n",
        "    n_classes = Y_score.shape[1]\n",
        "    false_positive_rate = dict()\n",
        "    true_positive_rate = dict()\n",
        "    roc_auc = dict()\n",
        "    for class_cntr in range(n_classes):\n",
        "        false_positive_rate[class_cntr], true_positive_rate[class_cntr], _ = roc_curve(Y_test[:, class_cntr],\n",
        "                                                                                       Y_score[:, class_cntr])\n",
        "        roc_auc[class_cntr] = auc(false_positive_rate[class_cntr], true_positive_rate[class_cntr])\n",
        "\n",
        "    # Compute micro-average ROC curve and ROC area\n",
        "    false_positive_rate[\"micro\"], true_positive_rate[\"micro\"], _ = roc_curve(Y_test.ravel(), Y_score.ravel())\n",
        "    roc_auc[\"micro\"] = auc(false_positive_rate[\"micro\"], true_positive_rate[\"micro\"])\n",
        "\n",
        "    return false_positive_rate, true_positive_rate, roc_auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JuCo5voGT-Jb"
      },
      "source": [
        "## Modified Optimizer for DP\n",
        "\n",
        "The optimizer below is a modification of the original from TF Privacy, [available here](https://github.com/tensorflow/privacy/blob/master/tensorflow_privacy/privacy/optimizers/dp_optimizer.py) to allow setting different values of noise multipliers and clipping factor on different steps of the optimization.\n",
        "\n",
        "The main modification lies on the `compute_gradients` method, which now includes:\n",
        "- *curr_noise_mult*: Current noise_multiplier\n",
        "- *curr_norm_clip*: Current L2 norm clipping factor\n",
        "\n",
        "On every step of the optimization we now additionally pass these parameters to control the privacy effects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hOBQELw7mo9Z",
        "colab": {}
      },
      "source": [
        "from absl import logging\n",
        "import collections\n",
        "\n",
        "from tensorflow_privacy.privacy.analysis import privacy_ledger\n",
        "from tensorflow_privacy.privacy.dp_query import gaussian_query\n",
        "\n",
        "def make_optimizer_class(cls):\n",
        "  \"\"\"Constructs a DP optimizer class from an existing one.\"\"\"\n",
        "  parent_code = tf.compat.v1.train.Optimizer.compute_gradients.__code__\n",
        "  child_code = cls.compute_gradients.__code__\n",
        "  GATE_OP = tf.compat.v1.train.Optimizer.GATE_OP  # pylint: disable=invalid-name\n",
        "  if child_code is not parent_code:\n",
        "    logging.warning(\n",
        "        'WARNING: Calling make_optimizer_class() on class %s that overrides '\n",
        "        'method compute_gradients(). Check to ensure that '\n",
        "        'make_optimizer_class() does not interfere with overridden version.',\n",
        "        cls.__name__)\n",
        "\n",
        "  class DPOptimizerClass(cls):\n",
        "    \"\"\"Differentially private subclass of given class cls.\"\"\"\n",
        "\n",
        "    _GlobalState = collections.namedtuple(\n",
        "      '_GlobalState', ['l2_norm_clip', 'stddev'])\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        dp_sum_query,\n",
        "        num_microbatches=None,\n",
        "        unroll_microbatches=False,\n",
        "        *args,  # pylint: disable=keyword-arg-before-vararg, g-doc-args\n",
        "        **kwargs):\n",
        "      \"\"\"Initialize the DPOptimizerClass.\n",
        "\n",
        "      Args:\n",
        "        dp_sum_query: DPQuery object, specifying differential privacy\n",
        "          mechanism to use.\n",
        "        num_microbatches: How many microbatches into which the minibatch is\n",
        "          split. If None, will default to the size of the minibatch, and\n",
        "          per-example gradients will be computed.\n",
        "        unroll_microbatches: If true, processes microbatches within a Python\n",
        "          loop instead of a tf.while_loop. Can be used if using a tf.while_loop\n",
        "          raises an exception.\n",
        "      \"\"\"\n",
        "      super(DPOptimizerClass, self).__init__(*args, **kwargs)\n",
        "      self._dp_sum_query = dp_sum_query\n",
        "      self._num_microbatches = num_microbatches\n",
        "      self._global_state = self._dp_sum_query.initial_global_state()\n",
        "      # TODO(b/122613513): Set unroll_microbatches=True to avoid this bug.\n",
        "      # Beware: When num_microbatches is large (>100), enabling this parameter\n",
        "      # may cause an OOM error.\n",
        "      self._unroll_microbatches = unroll_microbatches\n",
        "\n",
        "    def compute_gradients(self,\n",
        "                          loss,\n",
        "                          var_list,\n",
        "                          gate_gradients=GATE_OP,\n",
        "                          aggregation_method=None,\n",
        "                          colocate_gradients_with_ops=False,\n",
        "                          grad_loss=None,\n",
        "                          gradient_tape=None,\n",
        "                          curr_noise_mult=0,\n",
        "                          curr_norm_clip=1):\n",
        "\n",
        "      self._dp_sum_query = gaussian_query.GaussianSumQuery(curr_norm_clip, \n",
        "                                                           curr_norm_clip*curr_noise_mult)\n",
        "      self._global_state = self._dp_sum_query.make_global_state(curr_norm_clip, \n",
        "                                                                curr_norm_clip*curr_noise_mult)\n",
        "      \n",
        "\n",
        "      # TF is running in Eager mode, check we received a vanilla tape.\n",
        "      if not gradient_tape:\n",
        "        raise ValueError('When in Eager mode, a tape needs to be passed.')\n",
        "\n",
        "      vector_loss = loss()\n",
        "      if self._num_microbatches is None:\n",
        "        self._num_microbatches = tf.shape(input=vector_loss)[0]\n",
        "      sample_state = self._dp_sum_query.initial_sample_state(var_list)\n",
        "      microbatches_losses = tf.reshape(vector_loss, [self._num_microbatches, -1])\n",
        "      sample_params = (self._dp_sum_query.derive_sample_params(self._global_state))\n",
        "\n",
        "      def process_microbatch(i, sample_state):\n",
        "        \"\"\"Process one microbatch (record) with privacy helper.\"\"\"\n",
        "        microbatch_loss = tf.reduce_mean(input_tensor=tf.gather(microbatches_losses, [i]))\n",
        "        grads = gradient_tape.gradient(microbatch_loss, var_list)\n",
        "        sample_state = self._dp_sum_query.accumulate_record(sample_params, sample_state, grads)\n",
        "        return sample_state\n",
        "    \n",
        "      for idx in range(self._num_microbatches):\n",
        "        sample_state = process_microbatch(idx, sample_state)\n",
        "\n",
        "      if curr_noise_mult > 0:\n",
        "        grad_sums, self._global_state = (self._dp_sum_query.get_noised_result(sample_state, self._global_state))\n",
        "      else:\n",
        "        grad_sums = sample_state\n",
        "\n",
        "      def normalize(v):\n",
        "        return v / tf.cast(self._num_microbatches, tf.float32)\n",
        "\n",
        "      final_grads = tf.nest.map_structure(normalize, grad_sums)\n",
        "      grads_and_vars = final_grads#list(zip(final_grads, var_list))\n",
        "    \n",
        "      return grads_and_vars\n",
        "\n",
        "  return DPOptimizerClass\n",
        "\n",
        "\n",
        "def make_gaussian_optimizer_class(cls):\n",
        "  \"\"\"Constructs a DP optimizer with Gaussian averaging of updates.\"\"\"\n",
        "\n",
        "  class DPGaussianOptimizerClass(make_optimizer_class(cls)):\n",
        "    \"\"\"DP subclass of given class cls using Gaussian averaging.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        l2_norm_clip,\n",
        "        noise_multiplier,\n",
        "        num_microbatches=None,\n",
        "        ledger=None,\n",
        "        unroll_microbatches=False,\n",
        "        *args,  # pylint: disable=keyword-arg-before-vararg\n",
        "        **kwargs):\n",
        "      dp_sum_query = gaussian_query.GaussianSumQuery(\n",
        "          l2_norm_clip, l2_norm_clip * noise_multiplier)\n",
        "\n",
        "      if ledger:\n",
        "        dp_sum_query = privacy_ledger.QueryWithLedger(dp_sum_query,\n",
        "                                                      ledger=ledger)\n",
        "\n",
        "      super(DPGaussianOptimizerClass, self).__init__(\n",
        "          dp_sum_query,\n",
        "          num_microbatches,\n",
        "          unroll_microbatches,\n",
        "          *args,\n",
        "          **kwargs)\n",
        "\n",
        "    @property\n",
        "    def ledger(self):\n",
        "      return self._dp_sum_query.ledger\n",
        "\n",
        "  return DPGaussianOptimizerClass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwrPjV66eWjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GradientDescentOptimizer = tf.compat.v1.train.GradientDescentOptimizer\n",
        "DPGradientDescentGaussianOptimizer_NEW = make_gaussian_optimizer_class(GradientDescentOptimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpaCV2t-eWjj",
        "colab_type": "text"
      },
      "source": [
        "## Output setup\n",
        "\n",
        "Folder definitions for storing saved models and plots of generated images throughout training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IuUBjz5ZEn5D",
        "colab": {}
      },
      "source": [
        "# Edit to define folder\n",
        "result_dir = ROOT + '/My Drive/GAN/DPCGAN'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XOcY7Xxnplya",
        "colab": {}
      },
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "\n",
        "# Define checkpoint dir and prefix\n",
        "checkpoint_dir = result_dir + '/training_checkpoints'\n",
        "\n",
        "def checkpoint_name(title):  \n",
        "  checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt__\" + str(title))\n",
        "  return(checkpoint_prefix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o9Lzy_t_nOzd",
        "colab": {}
      },
      "source": [
        "# DO NOT EDIT THIS CELL\n",
        "\n",
        "images_dir = result_dir + '/images'\n",
        "\n",
        "def generate_and_save_images(title, model, epoch, test_input, test_label):\n",
        "  # Notice `training` is set to False: This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model([test_input, test_label], training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(2,10))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(10, 1, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "\n",
        "  plt.savefig(images_dir + '/' + title + '___image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gubUb2LBF2Hj",
        "colab": {}
      },
      "source": [
        "if not os.path.exists(result_dir):\n",
        "  os.makedirs(result_dir)\n",
        "\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "  os.makedirs(checkpoint_dir)\n",
        "\n",
        "if not os.path.exists(images_dir):\n",
        "  os.makedirs(images_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9Sb7NTLhqyh8"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Loading **MNIST** and creating hot encoding for labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D4yIv7MAqn9a",
        "outputId": "c708f4d9-e2e0-4e5d-cbfe-9a002759a0b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
        "train_labels = train_labels.reshape((60000, 1))\n",
        "COND_num_classes = 10 # Number of classes, set to 10 for MNIST dataset\n",
        "train_labels_vec = np.zeros((len(train_labels), COND_num_classes), dtype='float32')\n",
        "for i, label in enumerate(train_labels):\n",
        "    train_labels_vec[i, int(train_labels[i])] = 1.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ehOkmDl__ZyH"
      },
      "source": [
        "## C-GAN Models\n",
        "\n",
        "Both Generator and Discriminator follow simple architectures, with fully connected neural networks.\n",
        "\n",
        "We emphasize the use of C-GAN, therefore conditioning the models to the label information - notice the additional input on both networks below for labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byqg8h3FeWkA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Dimension of Latent Space - Does NOT affect DP-EPSILON\n",
        "Z_DIM = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PVBOYFJskMTZ",
        "colab": {}
      },
      "source": [
        "def make_generator_model_FCC():\n",
        "    # INPUT: label input\n",
        "    in_label = layers.Input(shape=(COND_num_classes,))\n",
        "\n",
        "    # INPUT: image generator input\n",
        "    in_lat = layers.Input(shape=(Z_DIM,))\n",
        "\n",
        "    # MERGE\n",
        "    merge = layers.concatenate([in_lat, in_label], axis=1)\n",
        "\n",
        "    ge1 = layers.Dense(128, use_bias=True)(merge)\n",
        "    ge1 = layers.ReLU()(ge1)\n",
        "\n",
        "    ge2 = layers.Dense(784, use_bias=True, activation=\"tanh\")(ge1)\n",
        "    out_layer = layers.Reshape((28, 28, 1))(ge2)\n",
        "\n",
        "    model = models.Model([in_lat, in_label], out_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "def make_discriminator_model_FCC():\n",
        "    # INPUT: Label\n",
        "    in_label = layers.Input(shape=(COND_num_classes,))\n",
        "\n",
        "    # INPUT: Image\n",
        "    in_image = layers.Input(shape=(28, 28, 1))\n",
        "    in_image_b = layers.Flatten()(in_image)\n",
        "\n",
        "    # MERGE\n",
        "    merge = layers.concatenate([in_image_b, in_label], axis=1)\n",
        "\n",
        "    ge1 = layers.Dense(128, use_bias=True)(merge)\n",
        "    ge1 = layers.ReLU()(ge1)\n",
        "\n",
        "    out_layer = layers.Dense(1, use_bias=True)(ge1)\n",
        "\n",
        "    model = models.Model([in_image, in_label], out_layer)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaloAxCSeWkH",
        "colab_type": "text"
      },
      "source": [
        "### Initiate and test models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOuBI2X2eWkI",
        "colab_type": "code",
        "outputId": "d17a420b-8890-424d-a504-b705f95b26ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "generator = make_generator_model_FCC()\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_1 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 110)          0           input_2[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          14208       concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "re_lu (ReLU)                    (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 784)          101136      re_lu[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 28, 28, 1)    0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 115,344\n",
            "Trainable params: 115,344\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmntW8vFeWkM",
        "colab_type": "code",
        "outputId": "57d0569b-514b-4f14-f581-d12e9c7d1e45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "discriminator = make_discriminator_model_FCC()\n",
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 784)          0           input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 794)          0           flatten[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 128)          101760      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "re_lu_1 (ReLU)                  (None, 128)          0           dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            129         re_lu_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 101,889\n",
            "Trainable params: 101,889\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "A_b5QPsCwEIW",
        "outputId": "3df4fd67-300e-43d3-bc3b-bee5e103f79f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "# Test GEN created\n",
        "noise = tf.Variable(tf.random.normal([1, Z_DIM]))\n",
        "noise_label = tf.Variable(np.array([0,0,1,0,0,0,0,0,0,0], dtype='float32').reshape((1,10)))\n",
        "print(noise.shape)\n",
        "print(noise_label.shape)\n",
        "generated_image = generator([noise, noise_label], training=False)\n",
        "plt.imshow(generated_image[0, :, :, 0], cmap='gray')\n",
        "\n",
        "# Test DISC created\n",
        "decision = discriminator([generated_image, noise_label])\n",
        "print(decision)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 100)\n",
            "(1, 10)\n",
            "tf.Tensor([[-0.10687535]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtGqeGSUeWkS",
        "colab_type": "text"
      },
      "source": [
        "### Loss and Updates\n",
        "\n",
        "- Please note that, during the training step of the Discriminator `train_step_DISC`, we **combine gradients** from both real and generated on a single update step into `sanitized_grads_and_vars`, following the approach from [Torkzadehmahani et al. 2019](http://openaccess.thecvf.com/content_CVPRW_2019/papers/CV-COPS/Torkzadehmahani_DP-CGAN_Differentially_Private_Synthetic_Data_and_Label_Generation_CVPRW_2019_paper.pdf).\n",
        "- When learning from the **real/training dataset** we <u>clip and add noise</u> to the gradients of the Discriminator.\n",
        "- When learning from the **generated data** we <u>only clip</u> the gradients of the Discriminator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Yj0E2qo3kHb0",
        "colab": {}
      },
      "source": [
        "cross_entropy_DISC = tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
        "cross_entropy_GEN = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "# Notice the use of `tf.function`: This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step_DISC(images, labels, noise, labels_to_gen):    \n",
        "    with tf.GradientTape(persistent=True) as disc_tape_real:\n",
        "        # This dummy call is needed to obtain the var list.\n",
        "        dummy = discriminator([images, labels], training=True)\n",
        "        var_list = discriminator.trainable_variables\n",
        "        \n",
        "        # In Eager mode, the optimizer takes a function that returns the loss.\n",
        "        def loss_fn_real():\n",
        "            real_output = discriminator([images, labels], training=True)\n",
        "            disc_real_loss = cross_entropy_DISC(tf.ones_like(real_output), real_output)\n",
        "            return disc_real_loss\n",
        "        \n",
        "        grads_and_vars_real = discriminator_optimizer.compute_gradients(loss_fn_real, \n",
        "                                                                        var_list, \n",
        "                                                                        gradient_tape=disc_tape_real, \n",
        "                                                                        curr_noise_mult=NOISE_MULT,\n",
        "                                                                        curr_norm_clip=NORM_CLIP)\n",
        "        \n",
        "        # In Eager mode, the optimizer takes a function that returns the loss.\n",
        "        def loss_fn_fake():\n",
        "            generated_images = generator([noise, labels_to_gen], training=True)\n",
        "            fake_output = discriminator([generated_images, labels_to_gen], training=True)\n",
        "            disc_fake_loss = cross_entropy_DISC(tf.zeros_like(fake_output), fake_output)\n",
        "            return disc_fake_loss\n",
        "        \n",
        "        grads_and_vars_fake = discriminator_optimizer.compute_gradients(loss_fn_fake,\n",
        "                                                                        var_list, \n",
        "                                                                        gradient_tape=disc_tape_real,\n",
        "                                                                        curr_noise_mult=0,\n",
        "                                                                        curr_norm_clip=NORM_CLIP)\n",
        "        disc_loss_r = loss_fn_real()\n",
        "        disc_loss_f = loss_fn_fake()\n",
        "        \n",
        "        s_grads_and_vars = [(grads_and_vars_real[idx] + grads_and_vars_fake[idx])\n",
        "                            for idx in range(len(grads_and_vars_real))]\n",
        "        sanitized_grads_and_vars = list(zip(s_grads_and_vars, var_list))\n",
        "        \n",
        "        discriminator_optimizer.apply_gradients(sanitized_grads_and_vars)\n",
        "        \n",
        "    return(disc_loss_r, disc_loss_f)\n",
        "\n",
        "# Notice the use of `tf.function`: This annotation causes the function to be \"compiled\".\n",
        "@tf.function\n",
        "def train_step_GEN(labels, noise):\n",
        "    with tf.GradientTape() as gen_tape:\n",
        "        generated_images = generator([noise, labels], training=True)\n",
        "        fake_output = discriminator([generated_images, labels], training=True)\n",
        "        # if the generator is performing well, the discriminator will classify the fake images as real (or 1)\n",
        "        gen_loss = cross_entropy_GEN(tf.ones_like(fake_output), fake_output)\n",
        "        \n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    \n",
        "    return(gen_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5AYc6qqeWkW",
        "colab_type": "text"
      },
      "source": [
        "### Train function definition\n",
        "\n",
        "- The Generator receives labels as input, in addition to noise, but since the labels are considered sensitive, as part of the training data, the Generator will **NOT** see/receive them.\n",
        "- In this sense, we get **uniform random samples** of the possible labels to pass to the Generator.\n",
        "- Therefore, we do **NOT** use DP-SGD on the Generator, since only the Discriminator trains using the sensitive training data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBYM_t3heWkX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(dataset, title, verbose):\n",
        "    for epoch in range(EPOCHS):\n",
        "        start = time.time()\n",
        "\n",
        "        i_gen = 0\n",
        "        for image_batch, label_batch in dataset:\n",
        "            if verbose:\n",
        "                print(\"Iteration: \" + str(i_gen+1))\n",
        "            \n",
        "            noise = tf.random.normal([BATCH_SIZE, Z_DIM])\n",
        "            labels_to_gen = _random_choice(labels_gen_vec, BATCH_SIZE)\n",
        "    \n",
        "            d_loss_r, d_loss_f = train_step_DISC(image_batch, label_batch, noise, labels_to_gen)\n",
        "            if verbose:\n",
        "                print(\"Loss DISC Real: \" + str(tf.reduce_mean(d_loss_r)))\n",
        "                print(\"Loss DISC Fake: \" + str(tf.reduce_mean(d_loss_f)))\n",
        "\n",
        "            if (i_gen + 1) % N_DISC == 0:\n",
        "                g_loss_f = train_step_GEN(labels_to_gen, noise)\n",
        "                if verbose:\n",
        "                    print(\"Loss GEN Fake:: \" + str(g_loss_f))\n",
        "\n",
        "            i_gen = i_gen + 1\n",
        "\n",
        "        # Produce images for the GIF as we go\n",
        "        display.clear_output(wait=True)\n",
        "        generate_and_save_images(title,\n",
        "                                 generator,\n",
        "                                 epoch + 1,\n",
        "                                 seed,\n",
        "                                 seed_labels)\n",
        "        \n",
        "        print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "        # Save the model\n",
        "        checkpoint.save(file_prefix = checkpoint_name(title + \"__epoch=\" + str(epoch) + \"__\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "RqMlVrs5G9bI"
      },
      "source": [
        "---\n",
        "\n",
        "## Parameters\n",
        "\n",
        "Specific parameters due to DP-SGD:\n",
        "- **NR_MICROBATCHES** (microbatches - int): Each batch of data (of size BATCH_SIZE) is split into smaller units called microbatches. So naturally NR_MICROBATCHES should evenly divide BATCH_SIZE. If NR_MICROBATCHES = BATCH_SIZE then every training example is a microbatch, clipped individually and with noise added to the average. As NR_MICROBATCHES decreases, we have more examples in a single microbatch, where *averaged* microbatches are clipped and noise is added to the *average* of averaged microbatches.\n",
        "- **NORM_CLIP** (l2_norm_clip - float) - The maximum Euclidean (L2) norm of each individual (or microbatch) gradient. To enforce such maximum norm gradients are clipped, which bounds the optimizer's sensitivity to individual training data.\n",
        "- **NOISE_MULT** (noise_multiplier - float) - The amount of noise sampled and added to gradients during training. Generally, more noise gives better privacy, which often, but not necessarily, lowers utility.\n",
        "    - Please have in mind that the actual noise added in practice is sampled from a Gaussian distribution with mean zero and standard deviation NORM_CLIP * NOISE_MULT.\n",
        "    - Therefore, a larger NORM_CLIP may pass more signal from the data via gradients, but it also increases the noise added to the gradients.\n",
        "    - TF Privacy's authors [have already pointed out](http://www.cleverhans.io/privacy/2019/03/26/machine-learning-with-differential-privacy-in-tensorflow.html) that setting NR_MICROBATCHES trades off performance (e.g. NR_MICROBATCHES = 1) with utility (e.g. NR_MICROBATCHES = BATCH_SIZE).\n",
        "- **DP_DELTA**: Delta from the DP definition. We emphasize that DP_DELTA needs to be smaller than 1/BUFFER_SIZE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zAn0CETqHzAz",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = 60000 # Total size of training data\n",
        "BATCH_SIZE = 600\n",
        "NR_MICROBATCHES = 600 # Each batch of data is split in smaller units called microbatches.\n",
        "\n",
        "\n",
        "NORM_CLIP = 1.1 # Does NOT affect EPSILON, but increases NOISE on gradients\n",
        "NOISE_MULT = 1.15\n",
        "\n",
        "\n",
        "DP_DELTA = 1e-5 # Needs to be smaller than 1/BUFFER_SIZE\n",
        "EPOCHS = 249\n",
        "\n",
        "\n",
        "N_DISC = 1 # Number of times we train DISC before training GEN once\n",
        "\n",
        "\n",
        "# Learning Rate for DISCRIMINATOR\n",
        "LR_DISC = tf.compat.v1.train.polynomial_decay(learning_rate=0.150,\n",
        "                                              global_step=tf.compat.v1.train.get_or_create_global_step(),\n",
        "                                              decay_steps=10000,\n",
        "                                              end_learning_rate=0.052,\n",
        "                                              power=1)\n",
        "\n",
        "if BATCH_SIZE % NR_MICROBATCHES != 0:\n",
        "    raise ValueError('Batch size should be an integer multiple of the number of microbatches')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBrUj8tneWkf",
        "colab_type": "text"
      },
      "source": [
        "### Get DP epsilon from parameters\n",
        "\n",
        "- Instead of updating and consulting the moments accountant on each step of training, we just previously check the epsilon we obtain from the given parameters.\n",
        "- Therefore, we can just quickly keep manually adjusting the parameters above to reach our desired epsilon below, and avoid extra computation during training.\n",
        "- Moreover, this allows a better understanding of the privacy implications of each parameter above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VocXhKB5lSEV",
        "outputId": "b8a3249b-f5fc-4d94-f1e4-8c2663132ee7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "# Obtain DP_EPSILON\n",
        "compute_dp_sgd_privacy.compute_dp_sgd_privacy(n = BUFFER_SIZE, \n",
        "                                              batch_size = BATCH_SIZE, \n",
        "                                              noise_multiplier = NOISE_MULT, \n",
        "                                              epochs = EPOCHS, \n",
        "                                              delta = DP_DELTA)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DP-SGD with sampling rate = 1% and noise_multiplier = 1.15 iterated over 24900 steps satisfies differential privacy with eps = 9.64 and delta = 1e-05.\n",
            "The optimal RDP order is 4.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9.643695567594444, 4.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "R1WvIihNKwXI",
        "outputId": "63769e35-083a-474e-9c09-fc71be7d391d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# SD of noise that will be added to gradients: sanity check\n",
        "NOISE_MULT*NORM_CLIP"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.265"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NMMbWnKoNa99"
      },
      "source": [
        "### Optimizers\n",
        "\n",
        "Instantiating optimizers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UovjSm3wKG3h",
        "colab": {}
      },
      "source": [
        "generator_optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "discriminator_optimizer = DPGradientDescentGaussianOptimizer_NEW(\n",
        "   learning_rate = LR_DISC,\n",
        "   l2_norm_clip = NORM_CLIP,\n",
        "   noise_multiplier = NOISE_MULT,\n",
        "   num_microbatches = NR_MICROBATCHES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "n6hVijBPlfg8"
      },
      "source": [
        "---\n",
        "\n",
        "## TRAINING\n",
        "\n",
        "- We emphasize here that when batching our training dataset, DP requires random shuffling.\n",
        "- To help track the progress of our GAN, we fix some seeds for labels and noise for the generator, and constantly plot the generated images. Below we create one seed for each of the 10 classes on MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIw5KKbyeWks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create/reinitiate models\n",
        "generator = make_generator_model_FCC()\n",
        "discriminator = make_discriminator_model_FCC()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tGI0EgGjoTrQ",
        "colab": {}
      },
      "source": [
        "# Create checkpoint structure\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                                 discriminator_optimizer=discriminator_optimizer,\n",
        "                                 generator=generator,\n",
        "                                 discriminator=discriminator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nTJgxxIqqw5n",
        "colab": {}
      },
      "source": [
        "tf.random.set_seed(1)\n",
        "\n",
        "# Batch and random shuffle training data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    (train_images, train_labels_vec)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "# Fix some seeds to help visualize progress\n",
        "seed = tf.random.normal([10, Z_DIM])\n",
        "seed_labels = tf.Variable(np.diag(np.full(10,1)).reshape((10,10)), dtype='float32')\n",
        "\n",
        "# To be used for sampling random labels to pass to generator\n",
        "labels_gen_vec = np.zeros((10, COND_num_classes), dtype='float32')\n",
        "for i in [0,1,2,3,4,5,6,7,8,9]:\n",
        "  labels_gen_vec[i, int(i)] = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BVDi7vlNqBlB",
        "colab": {}
      },
      "source": [
        "# GIVES CURRENT TRIAL A NAME - Suggestion: from parameters used\n",
        "training_title = 'eps9.6'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IL6rZttmrBOp",
        "outputId": "cdd783e3-4957-463f-e874-f05d6dc65815",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "# STARTS TRAINING\n",
        "train(train_dataset, training_title, False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADwAAAItCAYAAABl6RllAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 144x720 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Time for epoch 249 is 41.864766120910645 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dqYmjrrneWk4",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## VALIDATION\n",
        "\n",
        "We consider that the GAN training is performed specifically with the goal of publicly sharing the generated data to allow others to train a ML model. \n",
        "\n",
        "For this reason, we validate the results by training models on the generated data, and finally, after deciding on a single final GAN properly validated, we test the results by applying on the real test data the models trained on the generated data.\n",
        "\n",
        "\n",
        "### Choose model to use\n",
        "Select one of the trials (a fixed GAN) to validate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iat1MojxeWk6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EDIT THIS CELL\n",
        "# Choose checkpoint (model) to use:\n",
        "title = training_title\n",
        "epoch_ckp = EPOCHS - 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On0B_AUMeWk9",
        "colab_type": "code",
        "outputId": "a72fbf49-934f-4578-afa8-d757c4839982",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# DO NOT EDIT\n",
        "checkpoint_name = checkpoint_dir + \"/ckpt__\" + str(title) + \"__epoch=\" + str(epoch_ckp) + \"__-\" + str(EPOCHS)\n",
        "\n",
        "# RESTORE CHECKPOINT to variables defined on it\n",
        "checkpoint.restore(checkpoint_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f3f8003e0b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwQ0dU4reWk_",
        "colab_type": "text"
      },
      "source": [
        "### Generate images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9860snK5eWk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Number of images to generate\n",
        "N_GEN = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9DqLFm1Ix7cK",
        "colab": {}
      },
      "source": [
        "N_GEN_per_CLASS = np.int(N_GEN/10)\n",
        "\n",
        "tf.random.set_seed(10)\n",
        "noise_GEN = tf.random.normal([N_GEN, Z_DIM])\n",
        "labels_GEN = tf.Variable(np.array([1,0,0,0,0,0,0,0,0,0]*N_GEN_per_CLASS + \n",
        "                                   [0,1,0,0,0,0,0,0,0,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,1,0,0,0,0,0,0,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,0,1,0,0,0,0,0,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,0,0,1,0,0,0,0,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,0,0,0,1,0,0,0,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,0,0,0,0,1,0,0,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,0,0,0,0,0,1,0,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,0,0,0,0,0,0,1,0]*N_GEN_per_CLASS +\n",
        "                                   [0,0,0,0,0,0,0,0,0,1]*N_GEN_per_CLASS, \n",
        "                                   dtype='float32').reshape((N_GEN,10)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "jkV2uEM4ykxF",
        "colab": {}
      },
      "source": [
        "images_GEN = generator([noise_GEN, labels_GEN], training=False)\n",
        "images_flat = layers.Flatten()(images_GEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wqAmbPcSy_aP",
        "colab": {}
      },
      "source": [
        "labels_flat = tf.Variable(np.array([0]*N_GEN_per_CLASS + \n",
        "                                   [1]*N_GEN_per_CLASS +\n",
        "                                   [2]*N_GEN_per_CLASS +\n",
        "                                   [3]*N_GEN_per_CLASS +\n",
        "                                   [4]*N_GEN_per_CLASS +\n",
        "                                   [5]*N_GEN_per_CLASS +\n",
        "                                   [6]*N_GEN_per_CLASS +\n",
        "                                   [7]*N_GEN_per_CLASS +\n",
        "                                   [8]*N_GEN_per_CLASS +\n",
        "                                   [9]*N_GEN_per_CLASS, \n",
        "                                   dtype='float32').reshape((N_GEN,1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2npDQqY3zWHt",
        "colab": {}
      },
      "source": [
        "Y_train = labels_flat[:images_flat.shape[0]]\n",
        "X_train = images_flat\n",
        "\n",
        "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "Y_train_org = label_binarize(Y_train, classes=classes)\n",
        "Y_train_vec = layers.Flatten()(Y_train_org)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Qtb06W4a-nWD"
      },
      "source": [
        "### Get validation results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKhZFobreWlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Vanilla Neural Network\n",
        "\n",
        "tf.random.set_seed(100)\n",
        "classifier_NN = OneVsRestClassifier(MLPClassifier(random_state=2, alpha=1))\n",
        "NN_model = classifier_NN.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjlKXGnHbmpk",
        "colab_type": "code",
        "outputId": "8734db43-ef0c-43d7-916d-edc20b85f9f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ROC per class: Validating on REAL training dataset\n",
        "Y_score = NN_model.predict_proba(train_images.reshape(60000,28*28*1))\n",
        "false_positive_rate, true_positive_rate, roc_auc = compute_fpr_tpr_roc(np.array(train_labels_vec), Y_score)\n",
        "[str(au) + \" = \" + str(roc_auc[au]) for au in roc_auc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 = 0.9156175436348475',\n",
              " '1 = 0.9109113359493617',\n",
              " '2 = 0.8448357629269958',\n",
              " '3 = 0.8882383073487151',\n",
              " '4 = 0.8701179827357689',\n",
              " '5 = 0.7105516226318085',\n",
              " '6 = 0.8777944388928687',\n",
              " '7 = 0.9483760771858529',\n",
              " '8 = 0.8067643790586637',\n",
              " '9 = 0.8317681787985552',\n",
              " 'micro = 0.8623208510185186']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MR3vZhXeWlX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##### Logistic Regression\n",
        "\n",
        "tf.random.set_seed(100)\n",
        "classifier_LR = OneVsRestClassifier(LogisticRegression(solver='lbfgs', \n",
        "                                                       multi_class='multinomial', \n",
        "                                                       random_state=2))\n",
        "LR_model = classifier_LR.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SRt9hYmXDrc",
        "colab_type": "code",
        "outputId": "4928f7e8-b207-4fd0-f62d-205e0d8766f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ROC per class: Validating on REAL training dataset\n",
        "Y_score = LR_model.predict_proba(train_images.reshape(60000,28*28*1))\n",
        "false_positive_rate, true_positive_rate, roc_auc = compute_fpr_tpr_roc(np.array(train_labels_vec), Y_score)\n",
        "[str(au) + \" = \" + str(roc_auc[au]) for au in roc_auc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 = 0.9080131050804862',\n",
              " '1 = 0.9085025633043666',\n",
              " '2 = 0.688334958329813',\n",
              " '3 = 0.8476950761008604',\n",
              " '4 = 0.859092995921667',\n",
              " '5 = 0.6976934534213066',\n",
              " '6 = 0.8401491488042284',\n",
              " '7 = 0.9362736392739307',\n",
              " '8 = 0.7712583595504482',\n",
              " '9 = 0.6496058728444396',\n",
              " 'micro = 0.8156631838271604']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJwknz5neWlj",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "## TESTING\n",
        "\n",
        "Model trained on generated data is tested on the real MNIST test dataset to evaluate utility.\n",
        "\n",
        "### Load test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ms0HrSyw6KLi",
        "colab": {}
      },
      "source": [
        "(_, _), (X_test_org, Y_test_org) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "X_test_org = X_test_org.reshape(X_test_org.shape[0], 28, 28, 1).astype('float32')\n",
        "X_test_org = (X_test_org - 127.5) / 127.5 # Normalize the images to [-1, 1]\n",
        "\n",
        "Y_test_org = [int(y) for y in Y_test_org]\n",
        "classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
        "Y_test_org = label_binarize(Y_test_org, classes=classes)\n",
        "\n",
        "X_test = layers.Flatten()(X_test_org)\n",
        "Y_test = layers.Flatten()(Y_test_org)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6pDoU5x9eWln",
        "colab_type": "text"
      },
      "source": [
        "### Get test results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OhHFs0M85Yng",
        "outputId": "f34911ed-a9bf-4797-da24-240074d6ce5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "##### Vanilla Neural Network\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "classifier_NN = OneVsRestClassifier(MLPClassifier(random_state=2, alpha=1))\n",
        "NN_model2 = classifier_NN.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 = 0.9209843205574912',\n",
              " '1 = 0.9120826096787098',\n",
              " '2 = 0.8375744032183334',\n",
              " '3 = 0.8955799072677013',\n",
              " '4 = 0.8764040147810286',\n",
              " '5 = 0.7093873271612597',\n",
              " '6 = 0.8654857706485947',\n",
              " '7 = 0.9404502724429309',\n",
              " '8 = 0.8325209035635588',\n",
              " '9 = 0.8333318452248085',\n",
              " 'micro = 0.8635634855555555']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_NBzTjRcGws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ROC per class\n",
        "Y_score = NN_model2.predict_proba(X_test)\n",
        "false_positive_rate, true_positive_rate, roc_auc = compute_fpr_tpr_roc(np.array(Y_test), Y_score)\n",
        "[str(au) + \" = \" + str(roc_auc[au]) for au in roc_auc]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zZJJAJG07Zm2",
        "colab": {}
      },
      "source": [
        "##### Logistic Regression\n",
        "\n",
        "tf.random.set_seed(1)\n",
        "classifier_LR = OneVsRestClassifier(LogisticRegression(solver='lbfgs', \n",
        "                                                       multi_class='multinomial', \n",
        "                                                       random_state=2))\n",
        "LR_model2 = classifier_LR.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uztxYfmLb_ge",
        "colab_type": "code",
        "outputId": "e1c97e54-0a6f-439c-ab50-84a1eecee647",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ROC per class\n",
        "Y_score = LR_model2.predict_proba(X_test)\n",
        "false_positive_rate, true_positive_rate, roc_auc = compute_fpr_tpr_roc(np.array(Y_test), Y_score)\n",
        "[str(au) + \" = \" + str(roc_auc[au]) for au in roc_auc]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 = 0.9117935200687813',\n",
              " '1 = 0.91025092491136',\n",
              " '2 = 0.6826285665138406',\n",
              " '3 = 0.8533424376920451',\n",
              " '4 = 0.8643882183584854',\n",
              " '5 = 0.7010692319963132',\n",
              " '6 = 0.8342065489788087',\n",
              " '7 = 0.9285441217033192',\n",
              " '8 = 0.7948869817561042',\n",
              " '9 = 0.623646220827148',\n",
              " 'micro = 0.814876782222222']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}